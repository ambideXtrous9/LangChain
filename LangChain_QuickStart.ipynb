{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOE1bA+aaOczs5Wg54YTi5Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ambideXtrous9/LangChain/blob/main/LangChain_QuickStart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28m84PZSsDq4",
        "outputId": "c406a5aa-6c8c-4845-8d1f-7a7cfb382b30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m834.2/834.2 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain\n",
        "!pip install -q openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "jcLXLLI5suM0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = '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'"
      ],
      "metadata": {
        "id": "fpjU6rX9s1uX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Get Prediction from LLMs**"
      ],
      "metadata": {
        "id": "9nEhV9QEu-3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "seJnDsPStFb8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0.9) # temp = amount of randomness in model, if 0 -> deterministic, i.e same results everytime"
      ],
      "metadata": {
        "id": "YLSYrY59tnx5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"what are the top 5 travel destinations in India who loved to eat Biriyani ?\""
      ],
      "metadata": {
        "id": "NrU1eB8Vt7jA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6Cc0zxsuyel",
        "outputId": "9e651716-ac4f-4f10-b5ff-c41d524d6cbb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "1. Hyderabad, Telangana\n",
            "2. Lucknow, Uttar Pradesh\n",
            "3. Chennai, Tamil Nadu\n",
            "4. Calcutta, West Bengal\n",
            "5. Bhopal, Madhya Pradesh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JWsiu24ku0ni"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Prompt Template :** manage prompts for LLMs"
      ],
      "metadata": {
        "id": "mbwfJcQXvDGA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "8FqNJv5dvNea"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"food\"],\n",
        "    template= \"What are the top 5 travel destinations in India who loved to eat {food} ?\"\n",
        ")"
      ],
      "metadata": {
        "id": "zbZ4lIN0vXBu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompt.format(food='Rosogolla'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uspQs8wXwDNU",
        "outputId": "3bce3067-ab6e-4914-85c2-89be73cac1e1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What are the top 5 travel destinations in India who loved to eat Rosogolla ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm(prompt.format(food='Rosogolla')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dspnONaIwNM7",
        "outputId": "41179f0a-9b27-4afa-a992-d01c41656914"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "1. Kolkata - The sweet and syrupy rosogolla is a favorite among Kolkata's locals and tourists alike.\n",
            "\n",
            "2. Odisha - The birthplace of the traditional recipe of the rosogolla, Odisha is a must-visit if you're looking to enjoy this sweet.\n",
            "\n",
            "3. West Bengal - Home to some of the oldest rosogolla recipes, West Bengal is a great place to get a taste of this delicious sweet.\n",
            "\n",
            "4. Assam - Assam is known for its exquisite rosogollas. Try the traditional Oriya variant of the sweet here.\n",
            "\n",
            "5. Andhra Pradesh - Home to the well-known Tirupati Laddu, Andhra Pradesh is also a great place to find amazing rosogolla treats.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b-XsVdxcwSc8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Chains : Combine LLMs and Prompts in Multi-Step Workflows**\n",
        "\n",
        "## Chain to handle multiple workflow, handles multiple questions and answer and task "
      ],
      "metadata": {
        "id": "LYxx77E4xC0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain"
      ],
      "metadata": {
        "id": "HvT3zDhQxP1V"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"food\"],\n",
        "    template= \"What are the top 5 travel destinations in India who loved to eat {food} ?\"\n",
        ")"
      ],
      "metadata": {
        "id": "_ApzQlfGxzzY"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = LLMChain(llm=llm,prompt=prompt)"
      ],
      "metadata": {
        "id": "SRnbn2U-x_dW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain.run(\"Fish Curry\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQWaTJnKyMPx",
        "outputId": "b611430b-26a0-4029-dfe1-87b3301717ef"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "1. Goa\n",
            "2. Kerala\n",
            "3. Karnataka\n",
            "4. West Bengal\n",
            "5. Andhra Pradesh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "52cgxb-4yZQm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Agents :** Dynamically call chains based on User Input"
      ],
      "metadata": {
        "id": "y0KX3x28rdjp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q google-search-results"
      ],
      "metadata": {
        "id": "uux_GNnmsJhA"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import load_tools\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "tqiRL-WTsR2U"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0.8)"
      ],
      "metadata": {
        "id": "okET1Zidsw8z"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"SERPAPI_API_KEY\"] = '49180425656c659186fdab05b99c1ac10c4456b0d844343814cd38c4ef8b4500'"
      ],
      "metadata": {
        "id": "ezyxW2FYtPyS"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = load_tools([\"serpapi\",\"llm-math\"],llm=llm) # google search API"
      ],
      "metadata": {
        "id": "VbFTVvPttgIF"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = initialize_agent(tools,llm,agent=\"zero-shot-react-description\",verbose=True)"
      ],
      "metadata": {
        "id": "9Q4n97u5t06M"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"Who is the current leader of India ? What is the largest prime number smaller than his/her age ?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "yiJfqXW-uhhj",
        "outputId": "09b92cc2-dcfe-4631-8988-47cb310177e5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to find the age of the leader to answer both questions\n",
            "Action: Search\n",
            "Action Input: \"current leader of India\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mDroupadi Murmu\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m Now I need to find out how old he/she is\n",
            "Action: Search\n",
            "Action Input: \"Droupadi Murmu age\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m64 years\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m Now I can calculate the largest prime number smaller than the leader's age\n",
            "Action: Calculator\n",
            "Action Input: 64\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 64\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: The current leader of India is Droupadi Murmu and the largest prime number smaller than his/her age is 61.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The current leader of India is Droupadi Murmu and the largest prime number smaller than his/her age is 61.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fb-nT9PGu-7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Memory :** Add state to chains and agents "
      ],
      "metadata": {
        "id": "hRxQykGQvJhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import OpenAI, ConversationChain"
      ],
      "metadata": {
        "id": "3krga1b1vjYx"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0.8)"
      ],
      "metadata": {
        "id": "duE9Wze0v9rZ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation = ConversationChain(llm=llm,verbose=True)"
      ],
      "metadata": {
        "id": "cPmrTV76wEN-"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"Hi There\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "oPjS486rwPUZ",
        "outputId": "835fa715-277e-4bec-edd8-8fadacfc1ae5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: Hi There\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Hi there! It's nice to meet you! How can I help you today?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"What is your name ?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "EUvX574hwlWa",
        "outputId": "08d65ec2-3ba7-4016-fb36-bc9a5c786c39"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi There\n",
            "AI:  Hi there! It's nice to meet you! How can I help you today?\n",
            "Human: What is your name ?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" My name is AI-01. I'm an AI designed to help with common tasks. What can I do for you?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"write a short note for me in Bengali.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "yBm4OnEgwrsN",
        "outputId": "9d7a9ffe-6fdd-4787-b72f-43682176c10f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi There\n",
            "AI:  Hi there! It's nice to meet you! How can I help you today?\n",
            "Human: What is your name ?\n",
            "AI:  My name is AI-01. I'm an AI designed to help with common tasks. What can I do for you?\n",
            "Human: write a short note for me in Bengali.\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Unfortunately, I don't know how to write in Bengali. However, I can help you find someone who can. Would you like me to search for writers who can help you?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"Yes!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "X6k_-pXv7Fl1",
        "outputId": "c094a7ba-c14f-4170-f9d5-8914b2b12aac"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi There\n",
            "AI:  Hi there! It's nice to meet you! How can I help you today?\n",
            "Human: What is your name ?\n",
            "AI:  My name is AI-01. I'm an AI designed to help with common tasks. What can I do for you?\n",
            "Human: write a short note for me in Bengali.\n",
            "AI:  Unfortunately, I don't know how to write in Bengali. However, I can help you find someone who can. Would you like me to search for writers who can help you?\n",
            "Human: Yes!\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Great! I'll start searching right away. Please give me a few minutes to find some results.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LFniBUKq7LWW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}